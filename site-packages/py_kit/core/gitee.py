
import asyncio
import json
from cve_ease.sql import database, sanitize_string
from cve_ease.conf import gconfig
from cve_ease.models import SRPM, ISSUE, RESULT, PR, NVD
from cve_ease.core.gitee_api import GiteeAPI
from cve_ease.request import http
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy import and_
from datetime import datetime
from cve_ease.conf import settings


class Gitee():

    def __init__(self):
        self.session = database.new_session()
        self.srpms = self.session.query(SRPM).all()
        self.branch = gconfig['repodata']['upstream_distribution_version']

    def _from_commit_infos_get_release(self, commit_infos, ver, rel, is_kernel = False):
        if commit_infos is None:
            return None
        index = rel.find(".")
        if index != -1:
            rel = rel[0:index]
        release = f"{ver}-{rel}"
        if is_kernel:
            release = "4.19.90-2401.1.0.0233"
        print(release)
        for commit_info in commit_infos:
            if type(commit_info) is not dict:
                continue
            for line in commit_info["lines"]:
                if line.find(release) != -1:
                    return commit_info 
        return None

    def fetch_release_date(self, start_index = 1):
        srpms = self.session.query(SRPM).all()
        for index, srpm in enumerate(srpms):
            srpm.release_datetime = self.get_release_format_date(srpm.sname)
            self.session.commit()
            print(f"[{index + 1}/{len(srpms)}], sname: {srpm.sname}")
        print("fetch release date done !")

    def get_release_format_date(self, sname):
        gitee = GiteeAPI(sname)
        srpm = self.session.query(SRPM).filter(SRPM.sname == sname).first()
        commit_infos = gitee.get_release_blame()
        release_commit_info = self._from_commit_infos_get_release(commit_infos, srpm.sver, srpm.srelease, srpm.sname == "kernel")
        if release_commit_info is None:
            print(f"Maybe {srpm.sname} is not base on openEuler {self.branch}")
            return None

        release_date = release_commit_info["commit"]["author"]["date"]
        # release_format_date = release_date.replace("-", "")
        # release_format_date = release_format_date.replace(":", "")
        print(release_date)
        return release_date

    def fetch_all_pr(self, start_index = 1):
        print("gitee make_cache")
        tasks = []
        for srpm_index, srpm in enumerate(self.srpms):
            if srpm_index + 1 < start_index:
                continue
            total = self._process_per_srpm(srpm.sname)
            print(f"[{srpm_index + 1}/{len(self.srpms)}]: {srpm.sname}: total: {total}")
        

        print("** finish !!!")
    
    def fetch_one_pr(self, sname):
        srpm = self.session.query(SRPM).filter(SRPM.sname == sname).first()
        if srpm is None:
            print(f"{sname} is not exist")
            return
        total = self._process_per_srpm(srpm)
        print(f"{srpm.sname}: total: {total}, fetch done !")

    
    def _process_per_srpm(self, sname):
        print(f"processing {sname}...")
        gitee = GiteeAPI(sname)
        index = 1
        total = 0
        while index < 1000:
            # print(f"get_all_issue {index}")
            all_prs =  gitee.get_all_prs(index)
            if all_prs is None:
                print(f"get all prs failed, maybe {sname} is not belong to openEuler")
                break
            if len(all_prs) == 0:
                break
            for pr_info in all_prs:
                self._analyze_pr_info(
                    gitee = gitee,
                    pr_info = pr_info,
                )
            index += 1
            total += len(all_prs)
        return total


    def _analyze_pr_info(self, gitee, pr_info):
        spr = self.session.query(PR).filter(
            and_(
                PR.pr_number == pr_info["number"],
                PR.affected_component == gitee.repo
            )
        ).first()
        if spr is not None:
            return
        pr = PR()
        commits_url = pr_info["commits_url"]
        pr.affected_component = gitee.repo
        pr.pr_number = pr_info["number"]
        pr.pr_html_url = pr_info["html_url"]
        pr.pr_title = pr_info["title"]
        pr.close_related_issue = pr_info["close_related_issue"]
        pr.created_at = pr_info["created_at"]
        pr.merged_at = pr_info["merged_at"]
        pr.pr_patch_url = pr_info["patch_url"]
        pr.pr_commit_url = pr_info["commits_url"]
        pr.pr_state = pr_info["state"]
        pr.pr_ref = pr_info["base"]["ref"]

        commit_infos = self._analyze_commit_infos(gitee, commits_url)
        pr.commit_infos = commit_infos
        print(pr.pr_title)
        self.session.add(pr)
        self.session.commit()

    def _analyze_issue_info(self, gitee, issue_info):
        issue = ISSUE()
        issue.affected_component = gitee.repo
        issue.html_url = issue_info["html_url"]
        issue.number = issue_info["number"]
        issue.state = issue_info["state"]
        issue.title = issue_info["title"]
        issue.description = sanitize_string(issue_info['body'])
        if self.session.query(ISSUE).filter(ISSUE.number == issue.number).first() is not None:
            print(f"{issue.affected_component}: issue {issue.number} is exist, create_at: {issue.title}")
            return 
        labels = []
        for label in issue_info["labels"]:
            labels.append(label["name"])
        issue.labels = json.dumps(labels)
        issue.created_at = issue_info["created_at"]
        issue.finished_at = issue_info["finished_at"]
        issue.issue_type = issue_info["issue_type"]
        issue.issue_state = issue_info["issue_state"]
        try:
            self.session.add(issue)
            self.session.commit()
        except SQLAlchemyError as e:
            print(e)
            self.session.rollback()

        # pr_infos = gitee.get_pr_with_issue(issue_id=issue.number)
        # for pr_info in pr_infos:
        #     if pr_info["base"]["ref"] == self.branch:
        #         commits_url = pr_info["commits_url"]

        #         issue.pr_html_url = pr_info["html_url"]
        #         issue.pr_patch_url = pr_info["patch_url"]
        #         issue.pr_commit_url = pr_info["commits_url"]
        #         issue.pr_state = pr_info["state"]
        #         issue.pr_ref = pr_info["base"]["ref"]

        #         commit_infos = self._analyze_commit_infos(gitee, commits_url)
        #         issue.commit_infos = commit_infos
        #         print(issue.title)
                # self.session.add(issue)
                # self.session.commit()

        # print(f"issue info: {issue.affected_component}, title: {issue.title} number: {issue.description}")
        # print("affected_component: {}, html_url: {}, number: {}, state: {}, title: {}, labels: {}, created_at: {}, issue_type: {}, issue_state: {}, pr_html_url: {}, pr_patch_url: {}, pr_commit_url: {}, pr_state: {}, pr_ref: {}, \ncommit_infos: {}".format(
        #     issue.affected_component,
        #     issue.html_url,
        #     issue.number,
        #     issue.state,
        #     issue.title,
        #     issue.labels,
        #     issue.created_at,
        #     issue.issue_type,
        #     issue.issue_state,
        #     issue.pr_html_url,
        #     issue.pr_patch_url,
        #     issue.pr_commit_url,
        #     issue.pr_state,
        #     issue.pr_ref,
        #     issue.commit_infos
        # ))

    def fetch_all_issue(self, start_index = 1):
        prs = self.session.query(PR).all()
        for index, pr in enumerate(prs):
            self._process_per_pr(pr)
            print(f"[{index+1}/{len(prs)}], sname: {pr.affected_component}, title: {pr.pr_title}")

    def _process_per_pr(self, pr):
        gitee = GiteeAPI(pr.affected_component)
        issue_infos = gitee.get_issue_with_pr(pr_number=pr.pr_number)
        if pr.related_issues is None:
            related_issues = []
        else:
            related_issues = json.loads(pr.related_issues)
        for issue_info in issue_infos:
            if issue_info["number"] not in related_issues:
                related_issues.append(issue_info["number"])
            sissue = self.session.query(ISSUE).filter(ISSUE.number == issue_info["number"]).first()
            if sissue is not None:
                related_pr = json.loads(sissue.related_pr)
                if pr.pr_number not in related_pr:
                    related_pr.append(pr.pr_number)
                sissue.related_pr = json.dumps(related_pr)
                continue
            issue = ISSUE()
            issue.affected_component = pr.affected_component
            issue.html_url = issue_info["html_url"]
            issue.number = issue_info["number"]
            issue.state = issue_info["state"]
            issue.title = issue_info["title"]
            issue.description = sanitize_string(issue_info['body'])
            labels = []
            for label in issue_info["labels"]:
                labels.append(label["name"])
            issue.labels = json.dumps(labels)
            issue.created_at = issue_info["created_at"]
            issue.finished_at = issue_info["finished_at"]
            issue.issue_type = issue_info["issue_type"]
            issue.issue_state = issue_info["issue_state"]
            related_pr = []
            related_pr.append(pr.pr_number)
            issue.related_pr = json.dumps(related_pr)
            self.session.add(issue)

        if len(related_issues) > 0:
            pr.related_issues = json.dumps(related_issues)
        self.session.commit()

    def fetch_one_issue(self, sname):
        prs = self.session.query(PR).filter(PR.affected_component == sname).all()
        for index, pr in enumerate(prs):
            self._process_per_pr(pr)
            print(f"[{index+1}/{len(prs)}], sname: {pr.affected_component}")
        self.session.commit()
    def _analyze_commit_infos(self, gitee, commits_url):
        commit_infos =  gitee.get_pr_commits(commits_url=commits_url)
        commits = []
        for commit_info in commit_infos:
            commit_detail = gitee.get_commit_detail(commit_info["url"])
            files = []
            for file in commit_detail["files"]:
                files.append({
                    "file_name": file["filename"],
                    "status": file["status"],
                    "blob_url": file["blob_url"],
                    "raw_url": file["raw_url"],
                })

            commits.append({
                "url": commit_info["url"],
                "html_url": commit_info["html_url"],
                "commit_date": commit_detail["commit"]["committer"]["date"],
                "files": files,

            })


        return json.dumps(commits)

    def list_all_issue(self):
        cve_total = 0
        for srpm_index, srpm in enumerate(self.srpms):
            cve_total += self.list_issue(srpm.sname, srpm.release_datetime)
            # print(f"[{srpm_index+1}/ {len(self.srpms)}] sname: {srpm.sname}")
        print(f"cve_total: {cve_total}")

    def list_one_issue(self, sname):
        srpm = self.session.query(SRPM).filter(SRPM.sname == sname).first()
        total = self.list_issue(srpm.sname, srpm.release_datetime)
        print(f"total: {total}")

    def list_issue(self, sname, release_date):
        prs = self.session.query(PR).filter(PR.affected_component == sname).order_by(PR.merged_at).all()
        total = 0
        pr_total = 0
        if release_date == None:
            return 0
        release_datetime = datetime.fromisoformat(release_date)
        for index, pr in enumerate(prs):
            # pr_total += 1
            if pr.merged_at is None:
                continue
            print(f"{pr.pr_number}, sname: {sname}, pr_title: {pr.pr_title}, merged_at: {pr.merged_at}")
            merged_datetime = datetime.fromisoformat(pr.merged_at)
            if (merged_datetime < release_datetime):
                # print(f"has been merged pr, pr_title: {pr.pr_title}, merged_at: {pr.merged_at}")
                continue
            if pr.related_issues is None:
                continue
            # for related_issue in json.loads(pr.related_issues):
            #     issue = self.session.query(ISSUE).filter(ISSUE.number == related_issue).first()
            #     if issue.issue_type != "CVE和安全问题":
            #         continue
            #     if not issue.title.startswith("CVE-"):
            #         print("issue title not start with CVE-")
            #         continue
            #     print(f"issue title: {issue.title}, type: {issue.finished_at}")
            #     total += 1

        #     if pr.issue_type == "CVE和安全问题":
        #         if issue.related_pr is not None:
        #             # print(f"number: {issue.number}, title: {issue.title}, labels: {issue.labels}")
        #             total += 1
        # print(f"total: {total}")
        return total
        # print(f"pr_total: {pr_total}")
    
    def list_all_pr(self):
        pass

    def list_one_pr(self, sname):
        prs = self.session.query(PR).filter(PR.affected_component == sname).order_by(PR.merged_at).all()
        for pr in prs:
            print(f"sname: {sname}, pr_title: {pr.pr_title}")
        pass

    def test(self):
        cve_total = 0
        # results = self.session.query(RESULT).all()
        # for result in results:
        #     issue = self.session.query(ISSUE).filter(ISSUE.title.like(f"%{result.cveId}%")).first()
        #     if issue is None:
        #         print(f"cveId: {result.cveId}, sname: {result.affectedComponent}")
        #         unrecord_cve += 1
        res_set = set()
        for srpm_index, srpm in enumerate(self.srpms):
            prs = self.session.query(PR).filter(PR.affected_component == srpm.sname).order_by(PR.merged_at).all()
            total = 0
            pr_total = 0
            if srpm.release_datetime == None:
                continue
            release_datetime = datetime.fromisoformat(srpm.release_datetime)
            for index, pr in enumerate(prs):
                # pr_total += 1
                if pr.merged_at is None:
                    continue
                merged_datetime = datetime.fromisoformat(pr.merged_at)
                if (merged_datetime < release_datetime):
                    # print(f"has been merged pr, pr_title: {pr.pr_title}, merged_at: {pr.merged_at}")
                    continue
                # print(f"sname: {sname}, pr_title: {pr.pr_title}, merged_at: {pr.merged_at}")
                if pr.related_issues is None:
                    continue
                for related_issue in json.loads(pr.related_issues):
                    issue = self.session.query(ISSUE).filter(ISSUE.number == related_issue).first()
                    if issue.issue_type != "CVE和安全问题":
                        continue
                    if not issue.title.startswith("CVE-"):
                        print(f"issue title not start with CVE-, title: {issue.title}")
                        continue
                    # print(f"issue title: {issue.title}, type: {issue.finished_at}")
                    if issue.title in res_set:
                        # print(f"issue title: {issue.title}, sname: {issue.affected_component}")
                        continue
                    # cve = self.session.query(NVD).filter(NVD.cve_id == issue.title).first()
                    # if cve is None:
                    #     print(f"issue title: {issue.title}, not found in nvd")
                    res_set.add(issue.title)
                    total += 1

            #     if pr.issue_type == "CVE和安全问题":
            #         if issue.related_pr is not None:
            #             # print(f"number: {issue.number}, title: {issue.title}, labels: {issue.labels}")
            #             total += 1
            # print(f"total: {total}")
            cve_total += total


        # cve_total = 0
        # unrecord_cve = 0
        # for srpm_index, srpm in enumerate(self.srpms):
        #     issues = self.session.query(ISSUE).filter(ISSUE.affected_component == srpm.sname).order_by(ISSUE.created_at).all()
        #     total = 0
        #     for index, issue in enumerate(issues):
        #         if issue.issue_type == "CVE和安全问题":
        #             if issue.pr_html_url is not None:
        #                 # print(f"issue title: {issue.title}, labels: {issue.labels}, createdAt: {issue.created_at}")
        #                 cve = self.session.query(RESULT).filter(RESULT.cveId == issue.title).first()
        #                 if cve is None:
        #                     print(f"issue title: {issue.title}, sname: {issue.affected_component}, createdAt: {issue.created_at}, number: {issue.number}")
        #                     unrecord_cve += 1
        #                 total += 1
        #     if total == 0:
        #         continue
        #     # print(f"total: {total}")
        #     cve_total += total
        #     # print(f"[{srpm_index}/ {len(self.srpms)}] sname: {srpm.sname}")
        # print(f"cve_total: {cve_total}")
        print(f"res_set size: {len(res_set)}")
        print(f"cve_total: {cve_total}")

        
